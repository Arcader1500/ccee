# Mathematics & Statistics for AI Syllabus

## Chapter 1: Linear Algebra - Vectors
- Vectors: Definition, Operations (Add, Dot Product)
- Projections, Cosine Similarity, Orthogonality
- Norms, Vector Spaces, Linear Independence
- Basis and Rank

## Chapter 2: Linear Algebra - Matrices
- Matrix Operations: Addition, Multiplication, Transpose, Inverse
- Determinant, Trace, Rank
- Special Matrices: Symmetric, Diagonal, Orthogonal
- Matrix Decomposition: SVD (Singular Value Decomposition)
- Eigen Values & Eigenvectors
- PCA (Principal Component Analysis)

## Chapter 3: Calculus
- **Derivatives**: Scalar, Partial, Directional
- Gradient: Concept, Properties
- Gradients of Vector Valued Functions
- Jacobian
- Chain Rule, Taylor Series

## Chapter 4: Optimization
- Gradient Descent: Batch, Mini-Batch, Stochastic
- Local/Global Maxima/Minima, Saddle Points
- Convex Optimization
- Constrained Optimization (Lagrange Multipliers)
