[
    {
        "id": "pml_ch1_1",
        "text": "What is the primary difference between Supervised and Unsupervised learning?",
        "options": [
            {
                "id": "a",
                "text": "Unsupervised learning is faster and requires less computational power"
            },
            {
                "id": "b",
                "text": "Supervised learning uses labeled data while Unsupervised uses unlabeled data"
            },
            {
                "id": "c",
                "text": "Supervised learning is exclusively designed for regression tasks"
            },
            {
                "id": "d",
                "text": "Both approaches use the same training methodology"
            }
        ],
        "correctOptionId": "b",
        "hint": "Presence of target labels.",
        "explanation": "Supervised learning maps inputs to known outputs, while Unsupervised finds patterns in raw data."
    },
    {
        "id": "pml_ch1_2",
        "text": "What is 'Feature Engineering'?",
        "options": [
            {
                "id": "a",
                "text": "Managing and organizing engineering teams in software projects"
            },
            {
                "id": "b",
                "text": "Building and configuring computer hardware for ML applications"
            },
            {
                "id": "c",
                "text": "Selecting, manipulating, and transforming raw data into better features for ML models"
            },
            {
                "id": "d",
                "text": "Removing unnecessary data points from the dataset"
            }
        ],
        "correctOptionId": "c",
        "hint": "Data preparation.",
        "explanation": "Good feature engineering is often the key to high model performance."
    },
    {
        "id": "pml_ch1_3",
        "text": "What is 'Scaling' in data preprocessing?",
        "options": [
            {
                "id": "a",
                "text": "Increasing the resolution of images in the dataset"
            },
            {
                "id": "b",
                "text": "Removing outliers that fall outside acceptable ranges"
            },
            {
                "id": "c",
                "text": "Adding more samples to increase dataset size"
            },
            {
                "id": "d",
                "text": "Transforming features to similar ranges so no single feature dominates"
            }
        ],
        "correctOptionId": "d",
        "hint": "Standardization / Normalization.",
        "explanation": "Algorithms like KNN and SVM are sensitive to the magnitude of features."
    },
    {
        "id": "pml_ch1_4",
        "text": "What does PCA stand for in ML?",
        "options": [
            {
                "id": "a",
                "text": "Primary Color Adjustment"
            },
            {
                "id": "b",
                "text": "Personal Code Assistant"
            },
            {
                "id": "c",
                "text": "Principal Component Analysis"
            },
            {
                "id": "d",
                "text": "Private Cloud Access"
            }
        ],
        "correctOptionId": "c",
        "hint": "Dimensionality reduction.",
        "explanation": "PCA reduces the number of variables by creating new, uncorrelated components."
    },
    {
        "id": "pml_ch1_5",
        "text": "What is 't-SNE' used for?",
        "options": [
            {
                "id": "a",
                "text": "Building and training regression models"
            },
            {
                "id": "b",
                "text": "Visualizing high-dimensional data in 2D or 3D space"
            },
            {
                "id": "c",
                "text": "Compressing data for efficient storage"
            },
            {
                "id": "d",
                "text": "Classifying and filtering email messages"
            }
        ],
        "correctOptionId": "b",
        "hint": "Visualization tool.",
        "explanation": "Non-linear dimensionality reduction technique particularly well-suited for embedding high-dim data for visualization."
    },
    {
        "id": "pml_ch1_6",
        "text": "Which of these is a 'Regression' task?",
        "options": [
            {
                "id": "a",
                "text": "Grouping similar news articles together"
            },
            {
                "id": "b",
                "text": "Identifying whether an email is spam or not"
            },
            {
                "id": "c",
                "text": "Predicting tomorrow's stock price"
            },
            {
                "id": "d",
                "text": "Recognizing faces in photographs"
            }
        ],
        "correctOptionId": "c",
        "hint": "Predicting a continuous value.",
        "explanation": "Regression predicts a real number, while classification predicts a category."
    },
    {
        "id": "pml_ch1_7",
        "text": "Which of these is a 'Classification' task?",
        "options": [
            {
                "id": "a",
                "text": "Calculating the lifetime value of a customer"
            },
            {
                "id": "b",
                "text": "Estimating house prices based on features"
            },
            {
                "id": "c",
                "text": "Finding hidden patterns in DNA sequences"
            },
            {
                "id": "d",
                "text": "Predicting if a patient has a disease based on symptoms"
            }
        ],
        "correctOptionId": "d",
        "hint": "Predicting a discrete label.",
        "explanation": "Assigning an input to one of the predefined classes."
    },
    {
        "id": "pml_ch1_8",
        "text": "What is 'Standardization' (Z-score normalization)?",
        "options": [
            {
                "id": "a",
                "text": "Converting all values to binary (0 or 1)"
            },
            {
                "id": "b",
                "text": "Transforming data to have mean of 0 and standard deviation of 1"
            },
            {
                "id": "c",
                "text": "Creating new features from existing ones"
            },
            {
                "id": "d",
                "text": "Removing all negative values from the dataset"
            }
        ],
        "correctOptionId": "b",
        "hint": "Mean centering.",
        "explanation": "Formula: (x - mean) / std_dev."
    },
    {
        "id": "pml_ch1_9",
        "text": "What happens if you don't use 'Dimensionality Reduction' on 1000s of features?",
        "options": [
            {
                "id": "a",
                "text": "The model trains significantly faster"
            },
            {
                "id": "b",
                "text": "The dataset becomes too small to use"
            },
            {
                "id": "c",
                "text": "There is no noticeable effect on performance"
            },
            {
                "id": "d",
                "text": "Curse of Dimensionality - model becomes overfitted or computationally expensive"
            }
        ],
        "correctOptionId": "d",
        "hint": "Too many variables.",
        "explanation": "High-dimensional space makes samples very sparse and distance metrics lose meaning."
    },
    {
        "id": "pml_ch1_10",
        "text": "What is 'Data Imputation'?",
        "options": [
            {
                "id": "a",
                "text": "Exporting data to external systems"
            },
            {
                "id": "b",
                "text": "Sorting data in ascending or descending order"
            },
            {
                "id": "c",
                "text": "Deleting rows with incorrect values"
            },
            {
                "id": "d",
                "text": "Filling in missing values in a dataset"
            }
        ],
        "correctOptionId": "d",
        "hint": "Handling NaNs.",
        "explanation": "Can use mean, median, mode, or more complex methods like KNN imputation."
    },
    {
        "id": "pml_ch1_11",
        "text": "One-Hot encoding is typically used for?",
        "options": [
            {
                "id": "a",
                "text": "Continuous numerical variables"
            },
            {
                "id": "b",
                "text": "Image and video data"
            },
            {
                "id": "c",
                "text": "Categorical variables"
            },
            {
                "id": "d",
                "text": "Audio file processing"
            }
        ],
        "correctOptionId": "c",
        "hint": "Converting text labels to binary vectors.",
        "explanation": "Avoids imposing an artificial order on nominal categories (like Colors)."
    },
    {
        "id": "pml_ch1_12",
        "text": "What is 'Label Encoding'?",
        "options": [
            {
                "id": "a",
                "text": "Writing descriptive labels on data containers"
            },
            {
                "id": "b",
                "text": "Encrypting labels for security purposes"
            },
            {
                "id": "c",
                "text": "Removing all labels from the dataset"
            },
            {
                "id": "d",
                "text": "Assigning a unique integer to each category (e.g., Red=1, Green=2)"
            }
        ],
        "correctOptionId": "d",
        "hint": "Integers for categories.",
        "explanation": "Good for ordinal data where the order matters (e.g., Small=1, Medium=2, Large=3)."
    },
    {
        "id": "pml_ch1_13",
        "text": "What is 'Min-Max Scaling'?",
        "options": [
            {
                "id": "a",
                "text": "Identifying the smallest and largest values only"
            },
            {
                "id": "b",
                "text": "Scaling data to a fixed range, usually 0 to 1"
            },
            {
                "id": "c",
                "text": "Squaring all values in the dataset"
            },
            {
                "id": "d",
                "text": "Removing extreme values from the dataset"
            }
        ],
        "correctOptionId": "b",
        "hint": "Normalizing.",
        "explanation": "Formula: (x - min) / (max - min)."
    },
    {
        "id": "pml_ch1_14",
        "text": "Which of these is 'Unsupervised Learning'?",
        "options": [
            {
                "id": "a",
                "text": "Handwritten digit recognition using labeled images"
            },
            {
                "id": "b",
                "text": "Predicting house prices from historical data"
            },
            {
                "id": "c",
                "text": "Customer Segmentation using Clustering"
            },
            {
                "id": "d",
                "text": "Filtering spam emails based on training examples"
            }
        ],
        "correctOptionId": "c",
        "hint": "Grouping without labels.",
        "explanation": "Clustering finds natural groupings in data without human-provided labels."
    },
    {
        "id": "pml_ch1_15",
        "text": "What is an 'Outlier'?",
        "options": [
            {
                "id": "a",
                "text": "A data point that differs significantly from other observations"
            },
            {
                "id": "b",
                "text": "A data point with a value of exactly zero"
            },
            {
                "id": "c",
                "text": "Any missing value in the dataset"
            },
            {
                "id": "d",
                "text": "A correctly measured and validated data point"
            }
        ],
        "correctOptionId": "a",
        "hint": "Extreme value.",
        "explanation": "Outliers can skew ML models and are often handled during preprocessing."
    },
    {
        "id": "pml_ch1_16",
        "text": "The goal of PCA is to maximize?",
        "options": [
            {
                "id": "a",
                "text": "Training speed and efficiency"
            },
            {
                "id": "b",
                "text": "The total size of the dataset"
            },
            {
                "id": "c",
                "text": "Variance captured by components"
            },
            {
                "id": "d",
                "text": "The loss function value"
            }
        ],
        "correctOptionId": "c",
        "hint": "Preserving information.",
        "explanation": "PCA finds components that capture the most variance (information) in the data."
    },
    {
        "id": "pml_ch1_17",
        "text": "Which learning type uses 'Feedback' (Rewards and Penalties)?",
        "options": [
            {
                "id": "a",
                "text": "Supervised Learning with labeled examples"
            },
            {
                "id": "b",
                "text": "Reinforcement Learning through trial and error"
            },
            {
                "id": "c",
                "text": "Classification with categorical outputs"
            },
            {
                "id": "d",
                "text": "Data preprocessing and feature engineering"
            }
        ],
        "correctOptionId": "b",
        "hint": "Learning from interaction.",
        "explanation": "An agent learns by trial and error in an environment."
    },
    {
        "id": "pml_ch1_18",
        "text": "What is 'Garbage In, Garbage Out' (GIGO)?",
        "options": [
            {
                "id": "a",
                "text": "A file management system for deleting temporary files"
            },
            {
                "id": "b",
                "text": "Principle that poor quality input data leads to poor quality model output"
            },
            {
                "id": "c",
                "text": "A recycling program for old computer hardware"
            },
            {
                "id": "d",
                "text": "A method for cleaning office workspaces"
            }
        ],
        "correctOptionId": "b",
        "hint": "Importance of data quality.",
        "explanation": "No matter how good the algorithm, bad data results in a bad model."
    },
    {
        "id": "pml_ch1_19",
        "text": "What is 'Exploratory Data Analysis' (EDA)?",
        "options": [
            {
                "id": "a",
                "text": "Collecting new data from various sources"
            },
            {
                "id": "b",
                "text": "Building and training the final model"
            },
            {
                "id": "c",
                "text": "Permanently deleting unnecessary data"
            },
            {
                "id": "d",
                "text": "Summarizing and visualizing data to understand it before modeling"
            }
        ],
        "correctOptionId": "d",
        "hint": "Understanding the data.",
        "explanation": "Helps find patterns, outliers, and relationships."
    },
    {
        "id": "pml_ch1_20",
        "text": "The 'Elbow Method' is used to find?",
        "options": [
            {
                "id": "a",
                "text": "The optimal number of clusters (K)"
            },
            {
                "id": "b",
                "text": "The best model weights and parameters"
            },
            {
                "id": "c",
                "text": "Missing values in the dataset"
            },
            {
                "id": "d",
                "text": "The total error rate of predictions"
            }
        ],
        "correctOptionId": "a",
        "hint": "K-Means parameter tuning.",
        "explanation": "Identifies the point where adding more clusters gives diminishing returns."
    },
    {
        "id": "pml_ch1_21",
        "text": "In PCA, what is an 'Eigenvector' related to?",
        "options": [
            {
                "id": "a",
                "text": "The total number of rows in the dataset"
            },
            {
                "id": "b",
                "text": "The direction of the principal component"
            },
            {
                "id": "c",
                "text": "The magnitude of variance explained"
            },
            {
                "id": "d",
                "text": "The overall error rate of the model"
            }
        ],
        "correctOptionId": "b",
        "hint": "Direction.",
        "explanation": "Eigenvectors define the axes of the new component space."
    },
    {
        "id": "pml_ch1_22",
        "text": "In PCA, what is an 'Eigenvalue' related to?",
        "options": [
            {
                "id": "a",
                "text": "The total number of columns in the dataset"
            },
            {
                "id": "b",
                "text": "The computational speed of the algorithm"
            },
            {
                "id": "c",
                "text": "Amount of variance captured by the corresponding eigenvector"
            },
            {
                "id": "d",
                "text": "The memory usage during processing"
            }
        ],
        "correctOptionId": "c",
        "hint": "Strength of component.",
        "explanation": "Higher eigenvalues mean that component explains more variance."
    },
    {
        "id": "pml_ch1_23",
        "text": "What is the primary library for ML in Python?",
        "options": [
            {
                "id": "a",
                "text": "Requests for HTTP communication"
            },
            {
                "id": "b",
                "text": "Django for web development"
            },
            {
                "id": "c",
                "text": "Scikit-Learn for machine learning"
            },
            {
                "id": "d",
                "text": "OpenCV for computer vision"
            }
        ],
        "correctOptionId": "c",
        "hint": "The 'sklearn' tool.",
        "explanation": "Industry standard for classical ML algorithms and preprocessing."
    },
    {
        "id": "pml_ch1_24",
        "text": "Which of these is a dimensionality reduction technique?",
        "options": [
            {
                "id": "a",
                "text": "Only PCA (Principal Component Analysis)"
            },
            {
                "id": "b",
                "text": "Only LDA (Linear Discriminant Analysis)"
            },
            {
                "id": "c",
                "text": "Only SVD (Singular Value Decomposition)"
            },
            {
                "id": "d",
                "text": "All of the above techniques"
            }
        ],
        "correctOptionId": "d",
        "hint": "Many methods.",
        "explanation": "All these techniques help reduce the number of features."
    },
    {
        "id": "pml_ch1_25",
        "text": "What is 'Leakage' in ML?",
        "options": [
            {
                "id": "a",
                "text": "Losing data due to storage failures"
            },
            {
                "id": "b",
                "text": "Water damage to server hardware"
            },
            {
                "id": "c",
                "text": "When information from outside the training dataset is used to create the model"
            },
            {
                "id": "d",
                "text": "Using publicly available datasets"
            }
        ],
        "correctOptionId": "c",
        "hint": "Information bleed.",
        "explanation": "Data leakage leads to unrealistically high performance during testing."
    },
    {
        "id": "pml_ch1_26",
        "text": "Difference between training and test sets?",
        "options": [
            {
                "id": "a",
                "text": "Training is always the first half, test is the last half"
            },
            {
                "id": "b",
                "text": "Training contains features while test contains only labels"
            },
            {
                "id": "c",
                "text": "There is no meaningful difference between them"
            },
            {
                "id": "d",
                "text": "Training builds the model, test evaluates it on unseen data"
            }
        ],
        "correctOptionId": "d",
        "hint": "Evaluation strategy.",
        "explanation": "Must keep them separate to measure generalization."
    },
    {
        "id": "pml_ch1_27",
        "text": "Scaling is very important for which algorithm?",
        "options": [
            {
                "id": "a",
                "text": "Decision Trees and Random Forests"
            },
            {
                "id": "b",
                "text": "K-Nearest Neighbors (KNN)"
            },
            {
                "id": "c",
                "text": "Weighted random selection"
            },
            {
                "id": "d",
                "text": "Manual rule-based systems"
            }
        ],
        "correctOptionId": "b",
        "hint": "Distance based.",
        "explanation": "Algorithms calculating distances are heavily affected by feature magnitude."
    },
    {
        "id": "pml_ch1_28",
        "text": "What is 'Feature Selection'?",
        "options": [
            {
                "id": "a",
                "text": "Downloading features from external sources"
            },
            {
                "id": "b",
                "text": "Calculating new features from existing ones"
            },
            {
                "id": "c",
                "text": "Choosing the most relevant features and discarding redundant ones"
            },
            {
                "id": "d",
                "text": "Selecting none of the available features"
            }
        ],
        "correctOptionId": "c",
        "hint": "Keeping only useful cols.",
        "explanation": "Simplifies models and improves performance."
    },
    {
        "id": "pml_ch1_29",
        "text": "What is a 'Nominal' variable?",
        "options": [
            {
                "id": "a",
                "text": "A continuous numerical measurement"
            },
            {
                "id": "b",
                "text": "An integer-only data type"
            },
            {
                "id": "c",
                "text": "A sorted list of values"
            },
            {
                "id": "d",
                "text": "Categorical without implied order (e.g., Hair color)"
            }
        ],
        "correctOptionId": "d",
        "hint": "Name only.",
        "explanation": "Should be One-Hot encoded."
    },
    {
        "id": "pml_ch1_30",
        "text": "What is an 'Ordinal' variable?",
        "options": [
            {
                "id": "a",
                "text": "A number strictly between 0 and 1"
            },
            {
                "id": "b",
                "text": "Categorical with a clear order (e.g., High, Medium, Low)"
            },
            {
                "id": "c",
                "text": "A collection of random labels"
            },
            {
                "id": "d",
                "text": "Completely unordered data"
            }
        ],
        "correctOptionId": "b",
        "hint": "Order matters.",
        "explanation": "Can be Label Encoded to preserve hierarchy."
    }
]